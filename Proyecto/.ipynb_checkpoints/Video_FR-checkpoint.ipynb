{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e455bc48",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfacenet_pytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MTCNN, InceptionResnetV1\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytorch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "#from mtcnn.mtcnn import MTCNN\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    " \n",
    " #Cargar imagenes\n",
    "def cargar_imagen(directorio):\n",
    "    #return cv2.cvtColor(cv2.imread(f'{directorio}/{nombre}'),cv2.COLOR_BGR2RGB)\n",
    "    return cv2.imread(f'{directorio}',1)\n",
    "\n",
    " #----------------- Detectamos el rostro y exportamos los pixeles --------------------------\n",
    "    \n",
    "def reg_rostro(img, boxes):\n",
    "    #data = pyplot.imread(img)\n",
    "    #data = cargar_imagen(\"Conocidos\", \"varios.jpg\")\n",
    "    #cv2.imwrite(\"./Resultados/orig.jpg\",data)\n",
    "    solo_caras = []\n",
    "    for box in boxes:\n",
    "        cara_reg = img.crop((box))\n",
    "        cara_reg = np.asarray(cara_reg)\n",
    "        cara_reg = cv2.resize(cara_reg,dsize=(96,96)) #Guardamos la imagen con un tamaÃ±o de 96x96\n",
    "        cv2.imwrite(\"./Resultados/\"+str(len(solo_caras))+\".jpg\",cara_reg)\n",
    "        solo_caras.append(cara_reg)\n",
    "        \n",
    "    return solo_caras\n",
    "\n",
    "#help(MTCNN)\n",
    "path = \"./Conocidos/varios.jpg\"\n",
    "#pixeles = pyplot.imread(img)\n",
    "img = cargar_imagen(path)\n",
    "detector = MTCNN(keep_all=True)\n",
    "\n",
    "# Detect face\n",
    "boxes, probs = detector.detect(img)\n",
    "frame = Image.fromarray(img)\n",
    "caras = reg_rostro(frame, boxes)\n",
    "\n",
    "\n",
    "# This return a pretrained model that is vggface2\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "# Read data from folder\n",
    "\n",
    "dataset = datasets.ImageFolder('Conocidos') # photos folder path \n",
    "#dataset\n",
    "idx_to_class = {i:c for c,i in dataset.class_to_idx.items()} # accessing names of peoples from folder names\n",
    "#print(idx_to_class)\n",
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "loader = DataLoader(dataset, collate_fn=collate_fn)\n",
    "\n",
    "name_list = [] # list of names corrospoing to cropped photos\n",
    "embedding_list = [] # list of embeding matrix after conversion from cropped faces to embedding matrix using resnet\n",
    "\n",
    "for img, idx in loader:\n",
    "    print(img.size)\n",
    "    #Unlike other implementations, calling a facenet-pytorch MTCNN object directly with an image (i.e., using the forward method for those familiar with pytorch) will return torch tensors containing the detected face(s), rather than just the bounding boxes. This is to enable using the module easily as the first stage of a facial recognition pipeline, in which the faces are passed directly to an additional network or algorithm.\n",
    "    face, prob = detector(img, return_prob=True)\n",
    "    #print(\"face: \",face,\" prob:\",prob)\n",
    "    if face is not None and prob>0.92:\n",
    "        print(face.squeeze(1).shape)\n",
    "        #emb = resnet(face.unsqueeze(0))\n",
    "        emb = resnet(face.squeeze(1)) \n",
    "        embedding_list.append(emb.detach()) \n",
    "        name_list.append(idx_to_class[idx])        \n",
    "\n",
    "# save data\n",
    "data = [embedding_list, name_list] \n",
    "torch.save(data, 'data.pt') # saving data.pt file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578a8d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esc pressed, closing...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "detector = MTCNN(keep_all=True)\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "# Using webcam recognize face\n",
    "\n",
    "# loading data.pt file\n",
    "load_data = torch.load('data.pt') \n",
    "embedding_list = load_data[0] \n",
    "name_list = load_data[1] \n",
    "\n",
    "cam = cv2.VideoCapture(0) \n",
    "\n",
    "while not cam.isOpened():\n",
    "    cam = cv2.VideoCapture(\"./personas.mp4\")\n",
    "    cv2.waitKey(1000)\n",
    "    print (\"Wait for the header\")\n",
    "\n",
    "post_frame = cam.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"fail to grab frame, try again\")\n",
    "        # The next frame is not ready, so we try to read it again\n",
    "        cap.set(cv2.CV_CAP_PROP_POS_FRAMES, pos_frame-1)\n",
    "        print(\"frame is not ready\")\n",
    "        # It is better to wait for a while for the next frame to be ready\n",
    "        cv2.waitKey(1000)\n",
    "        break\n",
    "        \n",
    "    img = Image.fromarray(frame)\n",
    "    img_cropped_list, prob_list = detector(img, return_prob=True) \n",
    "    \n",
    "    if img_cropped_list is not None:\n",
    "        #return boxed faces\n",
    "        boxes, _ = detector.detect(img)\n",
    "                \n",
    "        for i, prob in enumerate(prob_list):\n",
    "            if prob>0.90:\n",
    "                emb = resnet(img_cropped_list[i].unsqueeze(0)).detach() \n",
    "                \n",
    "                dist_list = [] # list of matched distances, minimum distance is used to identify the person\n",
    "                \n",
    "                for idx, emb_db in enumerate(embedding_list):\n",
    "                    dist = torch.dist(emb, emb_db).item()\n",
    "                    dist_list.append(dist)\n",
    "\n",
    "                min_dist = min(dist_list) # get minumum dist value\n",
    "                min_dist_idx = dist_list.index(min_dist) # get minumum dist index\n",
    "                name = name_list[min_dist_idx] # get name corrosponding to minimum dist\n",
    "                \n",
    "                box = boxes[i]\n",
    "                #print(type(box), box)\n",
    "                original_frame = frame.copy() # storing copy of frame before drawing on it\n",
    "                \n",
    "                if min_dist<0.90:\n",
    "                    #bgr\n",
    "                    frame = cv2.putText(frame, str(name)+' '+str(min_dist), (int(box[0]),int(box[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (63, 0, 252),1, cv2.LINE_AA)\n",
    "                    #frame = cv2.putText(frame, 'Hola ' +name, (box[0],box[1]), cv2.FONT_HERSHEY_SIMPLEX, 1, (63, 0, 252),1, cv2.LINE_AA)\n",
    "\n",
    "                #print(int(box[0]),int(box[1]),int(box[2]),int(box[3]))\n",
    "                frame = cv2.rectangle(frame, (int(box[0]),int(box[1])) , (int(box[2]),int(box[3])), (13,214,53), 2)\n",
    "\n",
    "    cv2.imshow(\"IMG\", frame)\n",
    "\n",
    "    if cv2.waitKey(10) == 27:\n",
    "        break\n",
    "    #if cam.get(cv2.CAP_PROP_POS_FRAMEScv2.CV_CAP_PRcv2.CAP_PROP_POS_FRAMESv2.CV_CAP_PROP_FRAME_COUNT):\n",
    "        # If the number of captured frames is equal to the total number of frames,\n",
    "#        # we stop\n",
    "        break\n",
    "        \n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256==27: # ESC\n",
    "        print('Esc pressed, closing...')\n",
    "        break\n",
    "        \n",
    "    elif k%256==32: # space to save image\n",
    "        print('Enter your name :')\n",
    "        name = input()\n",
    "        \n",
    "        # create directory if not exists\n",
    "        if not os.path.exists('data2/'+name):\n",
    "            os.mkdir('data2/'+name)\n",
    "            \n",
    "        img_name = \"data2/{}/{}.jpg\".format(name, int(time.time()))\n",
    "        cv2.imwrite(img_name, original_frame)\n",
    "        print(\" saved: {}\".format(img_name))\n",
    "        \n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29c002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
